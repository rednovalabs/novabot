{
  "name": "hubot-markov",
  "description": "Build a markov model of everything Hubot hears.",
  "version": "1.3.0",
  "author": {
    "name": "Ash Wilson",
    "email": "smashwilson@gmail.com"
  },
  "contributors": [
    {
      "name": "Ash Wilson",
      "email": "smashwilson@gmail.com"
    },
    {
      "name": "Kyle Kelley",
      "email": "rgbkrk@gmail.com"
    },
    {
      "name": "Todd Berman",
      "email": "tberman@off.net"
    }
  ],
  "license": "MIT",
  "keywords": [
    "hubot",
    "hubot-scripts",
    "markov"
  ],
  "repository": {
    "type": "git",
    "url": "git://github.com/smashwilson/hubot-markov.git"
  },
  "bugs": {
    "url": "https://github.com/smashwilson/hubot-markov/issues"
  },
  "dependencies": {
    "coffee-script": "~1.6",
    "redis": "~0.9.1"
  },
  "devDependencies": {
    "mocha": "*",
    "chai": "*",
    "sinon-chai": "*",
    "sinon": "*"
  },
  "main": "index.coffee",
  "scripts": {
    "test": "script/test"
  },
  "readme": "# Hubot Markov Model\n\nGenerates a markov model based on everything that your Hubot sees in your\nchat.\n\n## Installing\n\n1. Add `hubot-markov` to your `package.json`:\n\n```json\n  \"dependencies\": {\n    \"hubot-markov\": \"~1.3.0\"\n  },\n```\n\n2. Require the module in `external-scripts.json`:\n\n```json\n[\"hubot-markov\"]\n```\n\n3. Run `npm update` and restart your Hubot.\n\n## Commands\n\nSaying anything at all in chat appends to the model. The robot is always\nwatching!\n\n`Hubot: markov` will randomly generate text based on the current contents of\nits model.\n\n`Hubot: markov your mother is a` will generate a random phrase seeded with\nthe phrase you give it. This command might output \"your mother is a classy\nlady\", for example. Remember: Hubot is an innocent soul, and what he says\nonly acts as a mirror for everything in your hearts.\n\n## Configuring\n\nThe Hubot markov model can optionally be configured by two environment\nvariables:\n\n`HUBOT_MARKOV_PLY` controls the *order* of the model that's built; effectively,\nhow many previous states (words) are considered to choose the next state. You\ncan bump this up if you'd like, but the default of 1 is both economical with\nstorage and maximally hilarious.\n\n`HUBOT_MARKOV_LEARN_MIN` controls the minimum length of a phrase that will\nbe used to train the model, default 1. Set this higher to avoid training your\nmodel with a bunch of immediate terminal transitions like \"lol\".\n\n`HUBOT_MARKOV_GENERATE_MAX` controls the maximum size of a markov chain that will be\ngenerated by the \"markov\" command.\n",
  "readmeFilename": "README.md",
  "homepage": "https://github.com/smashwilson/hubot-markov",
  "_id": "hubot-markov@1.3.0",
  "_from": "hubot-markov@1.3.0"
}
